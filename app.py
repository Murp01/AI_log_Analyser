"""
Logâ€‘Summariser â€” pure TensorFlow + GradioÂ 5
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 â€¢ Summarise long logs with a fineâ€‘tuned BART model
 â€¢ Works on CPU only (no PyTorch)
 â€¢ Supports sample logs, file upload, token counter, saveâ€‘toâ€‘txt
"""

from __future__ import annotations
from pathlib import Path
from typing import Tuple, Optional, Union
import tempfile

import gradio as gr
import tensorflow as tf
from transformers import AutoTokenizer, TFAutoModelForSeq2SeqLM

MODEL_ID = "VidhuMathur/bart-log-summarization"

# â”€â”€ 1Â Â·Â Load model & tokenizer (once) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
model = TFAutoModelForSeq2SeqLM.from_pretrained(MODEL_ID, from_pt=False)

# â”€â”€ 2Â Â·Â Sample logs for quick demos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
sample_logs = {
    "Test Run With Errors": """[INFO] Starting test run...
[INFO] TestLogin started
[ERROR] AssertionError: Expected True but got False
[INFO] TestLogin failed
[INFO] TestCheckout started
[INFO] TestCheckout passed
[WARNING] Deprecated API used in TestCart
[INFO] Test run complete""",
    "CI Pipeline Failure": """[INFO] Starting CI pipeline...
[INFO] Step 'Install dependencies' completed
[ERROR] Step 'Run unit tests' failed: 12 tests failed
[WARNING] Step 'Upload coverage' skipped due to failures
[INFO] Pipeline finished with errors""",
}

# â”€â”€ 3Â Â·Â Helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def preprocess(text: str) -> str:
    """Strip uninteresting lines (keep ERROR / FAIL / WARNING)."""
    focus = ("ERROR", "FAIL", "WARNING")
    lines = [ln for ln in text.splitlines() if any(k in ln.upper() for k in focus)]
    return "\n".join(lines) or text


def do_summarise(raw_log: str) -> Tuple[str, str]:
    """Return (summary, tokenâ€‘count string)."""
    if not raw_log.strip():
        return "", "âš ï¸Â No log text."

    cleaned = preprocess(raw_log)[:1024]  # tiny demo cap
    enc = tokenizer(cleaned, return_tensors="tf", truncation=True, max_length=1024)
    token_in = int(enc["input_ids"].shape[1])

    out_ids = model.generate(
        enc["input_ids"], max_length=80, min_length=20, num_beams=4, do_sample=False
    )
    summary = tokenizer.decode(out_ids[0], skip_special_tokens=True)
    return summary, f"**Input tokens:**Â {token_in}"


def save_to_file(text: str) -> Optional[str]:
    """Write summary to a tmp file and return its path for download."""
    if not text.strip():
        return None
    with tempfile.NamedTemporaryFile(delete=False, suffix=".txt", mode="w", encoding="utfâ€‘8") as fp:
        fp.write(text)
        return fp.name


def load_sample(name: str) -> str:
    return sample_logs.get(name, "")


def read_upload(file_obj: Union[bytes, str, Path, list, dict]) -> str:
    """Decode whatever Gradio passes for an uploaded file."""
    if not file_obj:
        return ""

    # Spaces (GradioÂ 5) wraps single upload in a list
    if isinstance(file_obj, list):
        file_obj = file_obj[0]

    # 1Â Â·Â Raw bytes (type="binary")
    if isinstance(file_obj, (bytes, bytearray)):
        return file_obj.decode("utfâ€‘8", errors="ignore")

    # 2Â Â·Â Pathâ€‘like
    if isinstance(file_obj, (str, Path)):
        try:
            return Path(file_obj).read_text(encoding="utfâ€‘8", errors="ignore")
        except Exception:
            return "âš ï¸Â Could not read file."

    # 3Â Â·Â Fileâ€‘like object (older local Gradio)
    if hasattr(file_obj, "read"):
        try:
            return file_obj.read().decode("utfâ€‘8", errors="ignore")
        except Exception:
            return "âš ï¸Â Could not read stream."

    # 4Â Â·Â FileData dict (edge case)
    if isinstance(file_obj, dict) and "data" in file_obj:
        import base64
        try:
            return base64.b64decode(file_obj["data"]).decode("utfâ€‘8", errors="ignore")
        except Exception:
            return "âš ï¸Â Could not decode FileData."

    return "âš ï¸Â Unsupported upload type."

# â”€â”€ 4Â Â·Â Gradio UI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
with gr.Blocks() as demo:
    gr.Markdown("# ğŸ§ Â AIÂ LogÂ Summariser")

    with gr.Row():
        drop = gr.Dropdown(choices=list(sample_logs), label="Sample log")
        load_btn = gr.Button("Load sample")

    file_up = gr.File(
        label="UploadÂ .logÂ /Â .txt",
        file_count="single",   # ensure only one file
        type="binary",         # send raw bytes (works in Spaces)
    )
    log_box = gr.Textbox(lines=15, label="Log input", placeholder="Paste log here")

    summarise_btn = gr.Button("Summarise")
    summary_box = gr.Textbox(label="Summary", lines=6)
    token_md = gr.Markdown()

    save_btn = gr.Button("Save summary")
    dl_link = gr.File(label="Download", visible=False)

    # Wire events
    load_btn.click(load_sample, drop, log_box)
    file_up.change(read_upload, file_up, log_box)
    summarise_btn.click(do_summarise, log_box, [summary_box, token_md])
    save_btn.click(save_to_file, summary_box, dl_link)

# â”€â”€ 5Â Â·Â Run â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    demo.launch()
